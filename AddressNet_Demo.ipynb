{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOO4HfmarjB4HSJDUElszRZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KarolChlasta/address-net/blob/master/AddressNet_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTiw-F2B4nb7",
        "outputId": "ffb65d59-b363-411d-8334-25ef89484def"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                          Version\n",
            "-------------------------------- ---------------------\n",
            "absl-py                          1.4.0\n",
            "address-net                      1.0\n",
            "aiohttp                          3.8.6\n",
            "aiosignal                        1.3.1\n",
            "alabaster                        0.7.13\n",
            "albumentations                   1.3.1\n",
            "altair                           4.2.2\n",
            "anyio                            3.7.1\n",
            "appdirs                          1.4.4\n",
            "argon2-cffi                      23.1.0\n",
            "argon2-cffi-bindings             21.2.0\n",
            "array-record                     0.5.0\n",
            "arviz                            0.15.1\n",
            "astor                            0.8.1\n",
            "astropy                          5.3.4\n",
            "astunparse                       1.6.3\n",
            "async-timeout                    4.0.3\n",
            "atpublic                         4.0\n",
            "attrs                            23.1.0\n",
            "audioread                        3.0.1\n",
            "autograd                         1.6.2\n",
            "Babel                            2.13.1\n",
            "backcall                         0.2.0\n",
            "beautifulsoup4                   4.11.2\n",
            "bidict                           0.22.1\n",
            "bigframes                        0.10.0\n",
            "bleach                           6.1.0\n",
            "blinker                          1.4\n",
            "blis                             0.7.11\n",
            "blosc2                           2.0.0\n",
            "bokeh                            3.2.2\n",
            "bqplot                           0.12.42\n",
            "branca                           0.6.0\n",
            "build                            1.0.3\n",
            "CacheControl                     0.13.1\n",
            "cachetools                       5.3.2\n",
            "catalogue                        2.0.10\n",
            "certifi                          2023.7.22\n",
            "cffi                             1.16.0\n",
            "chardet                          5.2.0\n",
            "charset-normalizer               3.3.1\n",
            "chex                             0.1.7\n",
            "click                            8.1.7\n",
            "click-plugins                    1.1.1\n",
            "cligj                            0.7.2\n",
            "cloudpickle                      2.2.1\n",
            "cmake                            3.27.7\n",
            "cmdstanpy                        1.2.0\n",
            "colorcet                         3.0.1\n",
            "colorlover                       0.3.0\n",
            "colour                           0.1.5\n",
            "community                        1.0.0b1\n",
            "condacolab                       0.1.7\n",
            "confection                       0.1.3\n",
            "cons                             0.4.6\n",
            "contextlib2                      21.6.0\n",
            "contourpy                        1.1.1\n",
            "cryptography                     41.0.5\n",
            "cufflinks                        0.17.3\n",
            "cupy-cuda11x                     11.0.0\n",
            "cvxopt                           1.3.2\n",
            "cvxpy                            1.3.2\n",
            "cycler                           0.12.1\n",
            "cymem                            2.0.8\n",
            "Cython                           3.0.4\n",
            "dask                             2023.8.1\n",
            "datascience                      0.17.6\n",
            "db-dtypes                        1.1.1\n",
            "dbus-python                      1.2.18\n",
            "debugpy                          1.6.6\n",
            "decorator                        4.4.2\n",
            "defusedxml                       0.7.1\n",
            "diskcache                        5.6.3\n",
            "distributed                      2023.8.1\n",
            "distro                           1.7.0\n",
            "dlib                             19.24.2\n",
            "dm-tree                          0.1.8\n",
            "docutils                         0.18.1\n",
            "dopamine-rl                      4.0.6\n",
            "duckdb                           0.8.1\n",
            "earthengine-api                  0.1.375\n",
            "easydict                         1.11\n",
            "ecos                             2.0.12\n",
            "editdistance                     0.6.2\n",
            "eerepr                           0.0.4\n",
            "en-core-web-sm                   3.6.0\n",
            "entrypoints                      0.4\n",
            "et-xmlfile                       1.1.0\n",
            "etils                            1.5.2\n",
            "etuples                          0.3.9\n",
            "exceptiongroup                   1.1.3\n",
            "fastai                           2.7.13\n",
            "fastcore                         1.5.29\n",
            "fastdownload                     0.0.7\n",
            "fastjsonschema                   2.18.1\n",
            "fastprogress                     1.0.3\n",
            "fastrlock                        0.8.2\n",
            "filelock                         3.12.4\n",
            "fiona                            1.9.5\n",
            "firebase-admin                   5.3.0\n",
            "Flask                            2.2.5\n",
            "flatbuffers                      23.5.26\n",
            "flax                             0.7.4\n",
            "folium                           0.14.0\n",
            "fonttools                        4.43.1\n",
            "frozendict                       2.3.8\n",
            "frozenlist                       1.4.0\n",
            "fsspec                           2023.6.0\n",
            "future                           0.18.3\n",
            "gast                             0.5.4\n",
            "gcsfs                            2023.6.0\n",
            "GDAL                             3.4.3\n",
            "gdown                            4.6.6\n",
            "geemap                           0.28.2\n",
            "gensim                           4.3.2\n",
            "geocoder                         1.38.1\n",
            "geographiclib                    2.0\n",
            "geopandas                        0.13.2\n",
            "geopy                            2.3.0\n",
            "gin-config                       0.5.0\n",
            "glob2                            0.7\n",
            "google                           2.0.3\n",
            "google-api-core                  2.11.1\n",
            "google-api-python-client         2.84.0\n",
            "google-auth                      2.17.3\n",
            "google-auth-httplib2             0.1.1\n",
            "google-auth-oauthlib             1.0.0\n",
            "google-cloud-bigquery            3.12.0\n",
            "google-cloud-bigquery-connection 1.12.1\n",
            "google-cloud-bigquery-storage    2.22.0\n",
            "google-cloud-core                2.3.3\n",
            "google-cloud-datastore           2.15.2\n",
            "google-cloud-firestore           2.11.1\n",
            "google-cloud-functions           1.13.3\n",
            "google-cloud-iam                 2.12.2\n",
            "google-cloud-language            2.9.1\n",
            "google-cloud-resource-manager    1.10.4\n",
            "google-cloud-storage             2.8.0\n",
            "google-cloud-translate           3.11.3\n",
            "google-colab                     1.0.0\n",
            "google-crc32c                    1.5.0\n",
            "google-pasta                     0.2.0\n",
            "google-resumable-media           2.6.0\n",
            "googleapis-common-protos         1.61.0\n",
            "googledrivedownloader            0.4\n",
            "graphviz                         0.20.1\n",
            "greenlet                         3.0.0\n",
            "grpc-google-iam-v1               0.12.6\n",
            "grpcio                           1.59.0\n",
            "grpcio-status                    1.48.2\n",
            "gspread                          3.4.2\n",
            "gspread-dataframe                3.3.1\n",
            "gym                              0.25.2\n",
            "gym-notices                      0.0.8\n",
            "h5netcdf                         1.2.0\n",
            "h5py                             3.9.0\n",
            "holidays                         0.35\n",
            "holoviews                        1.17.1\n",
            "html5lib                         1.1\n",
            "httpimport                       1.3.1\n",
            "httplib2                         0.22.0\n",
            "humanize                         4.7.0\n",
            "hyperopt                         0.2.7\n",
            "ibis-framework                   6.2.0\n",
            "idna                             3.4\n",
            "imageio                          2.31.6\n",
            "imageio-ffmpeg                   0.4.9\n",
            "imagesize                        1.4.1\n",
            "imbalanced-learn                 0.10.1\n",
            "imgaug                           0.4.0\n",
            "importlib-metadata               6.8.0\n",
            "importlib-resources              6.1.0\n",
            "imutils                          0.5.4\n",
            "inflect                          7.0.0\n",
            "iniconfig                        2.0.0\n",
            "install                          1.3.5\n",
            "intel-openmp                     2023.2.0\n",
            "ipyevents                        2.0.2\n",
            "ipyfilechooser                   0.6.0\n",
            "ipykernel                        5.5.6\n",
            "ipyleaflet                       0.17.4\n",
            "ipython                          7.34.0\n",
            "ipython-genutils                 0.2.0\n",
            "ipython-sql                      0.5.0\n",
            "ipytree                          0.2.2\n",
            "ipywidgets                       7.7.1\n",
            "itsdangerous                     2.1.2\n",
            "jax                              0.4.16\n",
            "jaxlib                           0.4.16+cuda11.cudnn86\n",
            "jeepney                          0.7.1\n",
            "jieba                            0.42.1\n",
            "Jinja2                           3.1.2\n",
            "joblib                           1.3.2\n",
            "jsonpickle                       3.0.2\n",
            "jsonschema                       4.19.1\n",
            "jsonschema-specifications        2023.7.1\n",
            "jupyter-client                   6.1.12\n",
            "jupyter-console                  6.1.0\n",
            "jupyter_core                     5.4.0\n",
            "jupyter-server                   1.24.0\n",
            "jupyterlab-pygments              0.2.2\n",
            "jupyterlab-widgets               3.0.9\n",
            "kaggle                           1.5.16\n",
            "keras                            2.14.0\n",
            "Keras-Applications               1.0.8\n",
            "Keras-Preprocessing              1.1.2\n",
            "keyring                          23.5.0\n",
            "kiwisolver                       1.4.5\n",
            "langcodes                        3.3.0\n",
            "launchpadlib                     1.10.16\n",
            "lazr.restfulclient               0.14.4\n",
            "lazr.uri                         1.0.6\n",
            "lazy_loader                      0.3\n",
            "libclang                         16.0.6\n",
            "librosa                          0.10.1\n",
            "lida                             0.0.10\n",
            "lightgbm                         4.1.0\n",
            "linkify-it-py                    2.0.2\n",
            "llmx                             0.0.15a0\n",
            "llvmlite                         0.39.1\n",
            "locket                           1.0.0\n",
            "logical-unification              0.4.6\n",
            "lxml                             4.9.3\n",
            "malloy                           2023.1058\n",
            "Markdown                         3.5\n",
            "markdown-it-py                   3.0.0\n",
            "MarkupSafe                       2.1.3\n",
            "matplotlib                       3.7.1\n",
            "matplotlib-inline                0.1.6\n",
            "matplotlib-venn                  0.11.9\n",
            "mdit-py-plugins                  0.4.0\n",
            "mdurl                            0.1.2\n",
            "miniKanren                       1.0.3\n",
            "missingno                        0.5.2\n",
            "mistune                          0.8.4\n",
            "mizani                           0.9.3\n",
            "mkl                              2023.2.0\n",
            "ml-dtypes                        0.2.0\n",
            "mlxtend                          0.22.0\n",
            "more-itertools                   10.1.0\n",
            "moviepy                          1.0.3\n",
            "mpmath                           1.3.0\n",
            "msgpack                          1.0.7\n",
            "multidict                        6.0.4\n",
            "multipledispatch                 1.0.0\n",
            "multitasking                     0.0.11\n",
            "murmurhash                       1.0.10\n",
            "music21                          9.1.0\n",
            "natsort                          8.4.0\n",
            "nbclassic                        1.0.0\n",
            "nbclient                         0.8.0\n",
            "nbconvert                        6.5.4\n",
            "nbformat                         5.9.2\n",
            "nest-asyncio                     1.5.8\n",
            "networkx                         3.2\n",
            "nibabel                          4.0.2\n",
            "nltk                             3.8.1\n",
            "notebook                         6.5.5\n",
            "notebook_shim                    0.2.3\n",
            "numba                            0.56.4\n",
            "numexpr                          2.8.7\n",
            "numpy                            1.23.5\n",
            "oauth2client                     4.1.3\n",
            "oauthlib                         3.2.2\n",
            "opencv-contrib-python            4.8.0.76\n",
            "opencv-python                    4.8.0.76\n",
            "opencv-python-headless           4.8.1.78\n",
            "openpyxl                         3.1.2\n",
            "opt-einsum                       3.3.0\n",
            "optax                            0.1.7\n",
            "orbax-checkpoint                 0.4.1\n",
            "osqp                             0.6.2.post8\n",
            "packaging                        23.2\n",
            "pandas                           1.5.3\n",
            "pandas-datareader                0.10.0\n",
            "pandas-gbq                       0.17.9\n",
            "pandas-stubs                     1.5.3.230304\n",
            "pandocfilters                    1.5.0\n",
            "panel                            1.3.0\n",
            "param                            2.0.0\n",
            "parso                            0.8.3\n",
            "parsy                            2.1\n",
            "partd                            1.4.1\n",
            "pathlib                          1.0.1\n",
            "pathy                            0.10.3\n",
            "patsy                            0.5.3\n",
            "peewee                           3.17.0\n",
            "pexpect                          4.8.0\n",
            "pickleshare                      0.7.5\n",
            "Pillow                           9.4.0\n",
            "pip                              23.1.2\n",
            "pip-tools                        6.13.0\n",
            "platformdirs                     3.11.0\n",
            "plotly                           5.15.0\n",
            "plotnine                         0.12.3\n",
            "pluggy                           1.3.0\n",
            "polars                           0.17.3\n",
            "pooch                            1.8.0\n",
            "portpicker                       1.5.2\n",
            "prefetch-generator               1.0.3\n",
            "preshed                          3.0.9\n",
            "prettytable                      3.9.0\n",
            "proglog                          0.1.10\n",
            "progressbar2                     4.2.0\n",
            "prometheus-client                0.17.1\n",
            "promise                          2.3\n",
            "prompt-toolkit                   3.0.39\n",
            "prophet                          1.1.5\n",
            "proto-plus                       1.22.3\n",
            "protobuf                         3.20.3\n",
            "psutil                           5.9.5\n",
            "psycopg2                         2.9.9\n",
            "ptyprocess                       0.7.0\n",
            "py-cpuinfo                       9.0.0\n",
            "py4j                             0.10.9.7\n",
            "pyarrow                          9.0.0\n",
            "pyasn1                           0.5.0\n",
            "pyasn1-modules                   0.3.0\n",
            "pycocotools                      2.0.7\n",
            "pycparser                        2.21\n",
            "pyct                             0.5.0\n",
            "pydantic                         1.10.13\n",
            "pydata-google-auth               1.8.2\n",
            "pydot                            1.4.2\n",
            "pydot-ng                         2.0.0\n",
            "pydotplus                        2.0.2\n",
            "PyDrive                          1.3.1\n",
            "PyDrive2                         1.6.3\n",
            "pyerfa                           2.0.1.1\n",
            "pygame                           2.5.2\n",
            "Pygments                         2.16.1\n",
            "PyGObject                        3.42.1\n",
            "PyJWT                            2.3.0\n",
            "pymc                             5.7.2\n",
            "pymystem3                        0.2.0\n",
            "PyOpenGL                         3.1.7\n",
            "pyOpenSSL                        23.2.0\n",
            "pyparsing                        3.1.1\n",
            "pyperclip                        1.8.2\n",
            "pyproj                           3.6.1\n",
            "pyproject_hooks                  1.0.0\n",
            "pyshp                            2.3.1\n",
            "PySocks                          1.7.1\n",
            "pytensor                         2.14.2\n",
            "pytest                           7.4.3\n",
            "python-apt                       0.0.0\n",
            "python-box                       7.1.1\n",
            "python-dateutil                  2.8.2\n",
            "python-louvain                   0.16\n",
            "python-slugify                   8.0.1\n",
            "python-utils                     3.8.1\n",
            "pytz                             2023.3.post1\n",
            "pyviz_comms                      3.0.0\n",
            "PyWavelets                       1.4.1\n",
            "PyYAML                           6.0.1\n",
            "pyzmq                            23.2.1\n",
            "qdldl                            0.1.7.post0\n",
            "qudida                           0.0.4\n",
            "ratelim                          0.1.6\n",
            "referencing                      0.30.2\n",
            "regex                            2023.6.3\n",
            "requests                         2.31.0\n",
            "requests-oauthlib                1.3.1\n",
            "requirements-parser              0.5.0\n",
            "rich                             13.6.0\n",
            "rpds-py                          0.10.6\n",
            "rpy2                             3.4.2\n",
            "rsa                              4.9\n",
            "scikit-image                     0.19.3\n",
            "scikit-learn                     1.2.2\n",
            "scipy                            1.11.3\n",
            "scooby                           0.9.2\n",
            "scs                              3.2.3\n",
            "seaborn                          0.12.2\n",
            "SecretStorage                    3.3.1\n",
            "Send2Trash                       1.8.2\n",
            "setuptools                       67.7.2\n",
            "shapely                          2.0.2\n",
            "six                              1.16.0\n",
            "sklearn-pandas                   2.2.0\n",
            "smart-open                       6.4.0\n",
            "sniffio                          1.3.0\n",
            "snowballstemmer                  2.2.0\n",
            "sortedcontainers                 2.4.0\n",
            "soundfile                        0.12.1\n",
            "soupsieve                        2.5\n",
            "soxr                             0.3.7\n",
            "spacy                            3.6.1\n",
            "spacy-legacy                     3.0.12\n",
            "spacy-loggers                    1.0.5\n",
            "Sphinx                           5.0.2\n",
            "sphinxcontrib-applehelp          1.0.7\n",
            "sphinxcontrib-devhelp            1.0.5\n",
            "sphinxcontrib-htmlhelp           2.0.4\n",
            "sphinxcontrib-jsmath             1.0.1\n",
            "sphinxcontrib-qthelp             1.0.6\n",
            "sphinxcontrib-serializinghtml    1.1.9\n",
            "SQLAlchemy                       2.0.22\n",
            "sqlglot                          17.16.2\n",
            "sqlparse                         0.4.4\n",
            "srsly                            2.4.8\n",
            "stanio                           0.3.0\n",
            "statsmodels                      0.14.0\n",
            "sympy                            1.12\n",
            "tables                           3.8.0\n",
            "tabulate                         0.9.0\n",
            "tbb                              2021.10.0\n",
            "tblib                            3.0.0\n",
            "tenacity                         8.2.3\n",
            "tensorboard                      1.12.2\n",
            "tensorboard-data-server          0.7.2\n",
            "tensorflow                       1.12.0\n",
            "tensorflow-datasets              4.9.3\n",
            "tensorflow-estimator             2.14.0\n",
            "tensorflow-gcs-config            2.14.0\n",
            "tensorflow-hub                   0.15.0\n",
            "tensorflow-io-gcs-filesystem     0.34.0\n",
            "tensorflow-metadata              1.14.0\n",
            "tensorflow-probability           0.22.0\n",
            "tensorstore                      0.1.45\n",
            "termcolor                        2.3.0\n",
            "terminado                        0.17.1\n",
            "text-unidecode                   1.3\n",
            "textblob                         0.17.1\n",
            "textdistance                     4.6.0\n",
            "tf-slim                          1.1.0\n",
            "thinc                            8.1.12\n",
            "threadpoolctl                    3.2.0\n",
            "tifffile                         2023.9.26\n",
            "tinycss2                         1.2.1\n",
            "toml                             0.10.2\n",
            "tomli                            2.0.1\n",
            "toolz                            0.12.0\n",
            "torch                            2.1.0+cu118\n",
            "torchaudio                       2.1.0+cu118\n",
            "torchdata                        0.7.0\n",
            "torchsummary                     1.5.1\n",
            "torchtext                        0.16.0\n",
            "torchvision                      0.16.0+cu118\n",
            "tornado                          6.3.2\n",
            "tqdm                             4.66.1\n",
            "traitlets                        5.7.1\n",
            "traittypes                       0.2.1\n",
            "triton                           2.1.0\n",
            "tweepy                           4.13.0\n",
            "typer                            0.9.0\n",
            "types-pytz                       2023.3.1.1\n",
            "types-setuptools                 68.2.0.0\n",
            "typing_extensions                4.5.0\n",
            "tzlocal                          5.2\n",
            "uc-micro-py                      1.0.2\n",
            "uritemplate                      4.1.1\n",
            "urllib3                          2.0.7\n",
            "vega-datasets                    0.9.0\n",
            "wadllib                          1.3.6\n",
            "wasabi                           1.1.2\n",
            "wcwidth                          0.2.8\n",
            "webcolors                        1.13\n",
            "webencodings                     0.5.1\n",
            "websocket-client                 1.6.4\n",
            "Werkzeug                         3.0.1\n",
            "wheel                            0.41.2\n",
            "widgetsnbextension               3.6.6\n",
            "wordcloud                        1.9.2\n",
            "wrapt                            1.14.1\n",
            "xarray                           2023.7.0\n",
            "xarray-einstats                  0.6.0\n",
            "xgboost                          2.0.1\n",
            "xlrd                             2.0.1\n",
            "xxhash                           3.4.1\n",
            "xyzservices                      2023.10.0\n",
            "yarl                             1.9.2\n",
            "yellowbrick                      1.5\n",
            "yfinance                         0.2.31\n",
            "zict                             3.0.0\n",
            "zipp                             3.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PITxq-ONzsf3",
        "outputId": "ce631e7b-0215-46d3-8c3b-bae80d0bdf68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/jasonrig/address-net.git\n",
            "  Cloning https://github.com/jasonrig/address-net.git to /tmp/pip-req-build-8csookdd\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/jasonrig/address-net.git /tmp/pip-req-build-8csookdd\n",
            "  Resolved https://github.com/jasonrig/address-net.git to commit 28e7c2de030bae56f81c66d7e640dcc2d04fdfb6\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from address-net==1.0) (1.23.5)\n",
            "Requirement already satisfied: textdistance in /usr/local/lib/python3.10/dist-packages (from address-net==1.0) (4.6.0)\n"
          ]
        }
      ],
      "source": [
        "pip install git+https://github.com/jasonrig/address-net.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install tensorflow-gpu==1.12.0\n",
        "#pip install -q condacolab\n",
        "#condacolab search python\n",
        "#!curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh\n",
        "\n",
        "!python -m pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.12.0-py3-none-any.whl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YN0bOWME0p3I",
        "outputId": "a69fe579-8c61-4f44-a149-2de2a77ca3ce"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==1.12.0\n",
            "  Using cached https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.12.0-py3-none-any.whl (62.0 MB)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==1.12.0) (1.4.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==1.12.0) (0.8.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==1.12.0) (0.5.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==1.12.0) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==1.12.0) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==1.12.0) (1.23.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==1.12.0) (1.16.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==1.12.0) (3.20.3)\n",
            "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==1.12.0) (1.12.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==1.12.0) (2.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==1.12.0) (1.59.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==1.12.0) (0.41.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications>=1.0.6->tensorflow==1.12.0) (3.9.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (3.5)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.10/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (3.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.10->tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (2.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional, Union, Callable, List\n",
        "from collections import OrderedDict\n",
        "\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import string\n",
        "\n",
        "import addressnet.lookups as lookups\n",
        "from addressnet.typo import generate_typo\n",
        "\n",
        "# Schema used to decode data from the TFRecord file\n",
        "_features = OrderedDict([\n",
        "    ('building_name', tf.io.FixedLenFeature([], tf.string)),\n",
        "    ('lot_number_prefix', tf.io.FixedLenFeature([], tf.string)),\n",
        "    ('lot_number', tf.io.FixedLenFeature([], tf.string)),\n",
        "    ('lot_number_suffix', tf.io.FixedLenFeature([], tf.string)),\n",
        "    ('flat_number_prefix', tf.io.FixedLenFeature([], tf.string)),\n",
        "    ('flat_number_suffix', tf.io.FixedLenFeature([], tf.string)),\n",
        "    ('level_number_prefix', tf.io.FixedLenFeature([], tf.string)),\n",
        "    ('level_number_suffix', tf.io.FixedLenFeature([], tf.string)),\n",
        "    ('number_first_prefix', tf.io.FixedLenFeature([], tf.string)),\n",
        "    ('number_first_suffix', tf.io.FixedLenFeature([], tf.string)),\n",
        "    ('number_last_prefix', tf.io.FixedLenFeature([], tf.string)),\n",
        "    ('number_last_suffix', tf.io.FixedLenFeature([], tf.string)),\n",
        "    ('street_name', tf.io.FixedLenFeature([], tf.string)),\n",
        "    ('locality_name', tf.io.FixedLenFeature([], tf.string)),\n",
        "    ('postcode', tf.io.FixedLenFeature([], tf.string)),\n",
        "    ('flat_number', tf.io.FixedLenFeature([], tf.int64)),\n",
        "    ('level_number', tf.io.FixedLenFeature([], tf.int64)),\n",
        "    ('number_first', tf.io.FixedLenFeature([], tf.int64)),\n",
        "    ('number_last', tf.io.FixedLenFeature([], tf.int64)),\n",
        "    ('flat_type', tf.io.FixedLenFeature([], tf.int64)),\n",
        "    ('level_type', tf.io.FixedLenFeature([], tf.int64)),\n",
        "    ('street_type_code', tf.io.FixedLenFeature([], tf.int64)),\n",
        "    ('street_suffix_code', tf.io.FixedLenFeature([], tf.int64)),\n",
        "    ('state_abbreviation', tf.io.FixedLenFeature([], tf.int64)),\n",
        "    ('latitude', tf.io.FixedLenFeature([], tf.float32)),\n",
        "    ('longitude', tf.io.FixedLenFeature([], tf.float32))\n",
        "])\n",
        "\n",
        "# List of fields used as labels in the training data\n",
        "labels_list = [\n",
        "    'building_name',  # 1\n",
        "    'level_number_prefix',  # 2\n",
        "    'level_number',  # 3\n",
        "    'level_number_suffix',  # 4\n",
        "    'level_type',  # 5\n",
        "    'flat_number_prefix',  # 6\n",
        "    'flat_number',  # 7\n",
        "    'flat_number_suffix',  # 8\n",
        "    'flat_type',  # 9\n",
        "    'number_first_prefix',  # 10\n",
        "    'number_first',  # 11\n",
        "    'number_first_suffix',  # 12\n",
        "    'number_last_prefix',  # 13\n",
        "    'number_last',  # 14\n",
        "    'number_last_suffix',  # 15\n",
        "    'street_name',  # 16\n",
        "    'street_suffix_code',  # 17\n",
        "    'street_type_code',  # 18\n",
        "    'locality_name',  # 19\n",
        "    'state_abbreviation',  # 20\n",
        "    'postcode'  # 21\n",
        "]\n",
        "# Number of labels in total (+1 for the blank category)\n",
        "n_labels = len(labels_list) + 1\n",
        "\n",
        "# Allowable characters for the encoded representation\n",
        "vocab = list(string.digits + string.ascii_lowercase + string.punctuation + string.whitespace)\n",
        "\n",
        "\n",
        "def vocab_lookup(characters: str) -> (int, np.ndarray):\n",
        "    \"\"\"\n",
        "    Converts a string into a list of vocab indices\n",
        "    :param characters: the string to convert\n",
        "    :param training: if True, artificial typos will be introduced\n",
        "    :return: the string length and an array of vocab indices\n",
        "    \"\"\"\n",
        "    result = list()\n",
        "    for c in characters.lower():\n",
        "        try:\n",
        "            result.append(vocab.index(c) + 1)\n",
        "        except ValueError:\n",
        "            result.append(0)\n",
        "    return len(characters), np.array(result, dtype=np.int64)\n",
        "\n",
        "\n",
        "def decode_data(record: List[Union[str, int, float]]) -> Union[str, int, float]:\n",
        "    \"\"\"\n",
        "    Decodes a record from the tfrecord file by converting all strings to UTF-8 encoding, and any numeric field with\n",
        "    a value of -1 to None.\n",
        "    :param record: the record to decode\n",
        "    :return: an iterator for yielding the decoded fields\n",
        "    \"\"\"\n",
        "    for item in record:\n",
        "        try:\n",
        "            # Attempt to treat the item in the record as a string\n",
        "            yield item.decode(\"UTF-8\")\n",
        "        except AttributeError:\n",
        "            # Treat the item as a number and encode -1 as None (see generate_tf_records.py)\n",
        "            yield item if item != -1 else None\n",
        "\n",
        "\n",
        "def labels(text: Union[str, int], field_name: Optional[str], mutate: bool = True) -> (str, np.ndarray):\n",
        "    \"\"\"\n",
        "    Generates a numpy matrix labelling each character by field type. Strings have artificial typos introduced if\n",
        "    mutate == True\n",
        "    :param text: the text to label\n",
        "    :param field_name: the name of the field to which the text belongs, or None if the label is blank\n",
        "    :param mutate: introduce artificial typos\n",
        "    :return: the original text and the numpy matrix of labels\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure the input is a string, encoding None to an empty to string\n",
        "    if text is None:\n",
        "        text = ''\n",
        "    else:\n",
        "        # Introduce artificial typos if mutate == True\n",
        "        text = generate_typo(str(text)) if mutate else str(text)\n",
        "    labels_matrix = np.zeros((len(text), n_labels), dtype=np.bool)\n",
        "\n",
        "    # If no field is supplied, then encode the label using the blank category\n",
        "    if field_name is None:\n",
        "        labels_matrix[:, 0] = True\n",
        "    else:\n",
        "        labels_matrix[:, labels_list.index(field_name) + 1] = True\n",
        "    return text, labels_matrix\n",
        "\n",
        "\n",
        "def random_separator(min_length: int = 1, max_length: int = 3, possible_sep_chars: Optional[str] = r\",./\\  \") -> str:\n",
        "    \"\"\"\n",
        "    Generates a space-padded separator of random length using a random character from possible_sep_chars\n",
        "    :param min_length: minimum length of the separator\n",
        "    :param max_length: maximum length of the separator\n",
        "    :param possible_sep_chars: string of possible characters to use for the separator\n",
        "    :return: the separator string\n",
        "    \"\"\"\n",
        "    chars = [\" \"] * random.randint(min_length, max_length)\n",
        "    if len(chars) > 0 and possible_sep_chars:\n",
        "        sep_char = random.choice(possible_sep_chars)\n",
        "        chars[random.randrange(len(chars))] = sep_char\n",
        "    return ''.join(chars)\n",
        "\n",
        "\n",
        "def join_labels(lbls: [np.ndarray], sep: Union[str, Callable[..., str]] = \" \") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Concatenates a series of label matrices with a separator\n",
        "    :param lbls: a list of numpy matrices\n",
        "    :param sep: the separator string or function that returns the sep string\n",
        "    :return: the concatenated labels\n",
        "    \"\"\"\n",
        "    if len(lbls) < 2:\n",
        "        return lbls\n",
        "\n",
        "    joined_labels = None\n",
        "    sep_str = None\n",
        "\n",
        "    # if `sep` is not a function, set the separator (`sep_str`) to `sep`, otherwise leave as None\n",
        "    if not callable(sep):\n",
        "        sep_str = sep\n",
        "\n",
        "    for l in lbls:\n",
        "        if joined_labels is None:\n",
        "            joined_labels = l\n",
        "        else:\n",
        "            # If `sep` is a function, call it on each iteration\n",
        "            if callable(sep):\n",
        "                sep_str = sep()\n",
        "\n",
        "            # Skip zero-length labels\n",
        "            if l.shape[0] == 0:\n",
        "                continue\n",
        "            elif sep_str is not None and len(sep_str) > 0 and joined_labels.shape[0] > 0:\n",
        "                # Join using sep_str if it's present and non-zero in length\n",
        "                joined_labels = np.concatenate([joined_labels, labels(sep_str, None, mutate=False)[1], l], axis=0)\n",
        "            else:\n",
        "                # Otherwise, directly concatenate the labels\n",
        "                joined_labels = np.concatenate([joined_labels, l], axis=0)\n",
        "\n",
        "    assert joined_labels is not None, \"No labels were joined!\"\n",
        "    assert joined_labels.shape[1] == n_labels, \"The number of labels generated was unexpected: got %i but wanted %i\" % (\n",
        "        joined_labels.shape[1], n_labels)\n",
        "\n",
        "    return joined_labels\n",
        "\n",
        "\n",
        "def join_str_and_labels(parts: [(str, np.ndarray)], sep: Union[str, Callable[..., str]] = \" \") -> (str, np.ndarray):\n",
        "    \"\"\"\n",
        "    Joins the strings and labels using the given separator\n",
        "    :param parts: a list of string/label tuples\n",
        "    :param sep: a string or function that returns the string to be used as a separator\n",
        "    :return: the joined string and labels\n",
        "    \"\"\"\n",
        "    # Keep only the parts with strings of length > 0\n",
        "    parts = [p for p in parts if len(p[0]) > 0]\n",
        "\n",
        "    # If there are no parts at all, return an empty string an array of shape (0, n_labels)\n",
        "    if len(parts) == 0:\n",
        "        return '', np.zeros((0, n_labels))\n",
        "    # If there's only one part, just give it back as-is\n",
        "    elif len(parts) == 1:\n",
        "        return parts[0]\n",
        "\n",
        "    # Pre-generate the separators - this is important if `sep` is a function returning non-deterministic results\n",
        "    n_sep = len(parts) - 1\n",
        "    if callable(sep):\n",
        "        seps = [sep() for _ in range(n_sep)]\n",
        "    else:\n",
        "        seps = [sep] * n_sep\n",
        "    seps += ['']\n",
        "\n",
        "    # Join the strings using the list of separators\n",
        "    strings = ''.join(sum([(s[0][0], s[1]) for s in zip(parts, seps)], ()))\n",
        "\n",
        "    # Join the labels using an iterator function\n",
        "    sep_iter = iter(seps)\n",
        "    lbls = join_labels([s[1] for s in parts], sep=lambda: next(sep_iter))\n",
        "\n",
        "    assert len(strings) == lbls.shape[0], \"string length %i (%s), label length %i using sep %s\" % (\n",
        "        len(strings), strings, lbls.shape[0], seps)\n",
        "    return strings, lbls\n",
        "\n",
        "\n",
        "def choose(option1: Callable = lambda: None, option2: Callable = lambda: None):\n",
        "    \"\"\"\n",
        "    Randomly run either option 1 or option 2\n",
        "    :param option1: a possible function to run\n",
        "    :param option2: another possible function to run\n",
        "    :return: the result of the function\n",
        "    \"\"\"\n",
        "    if random.getrandbits(1):\n",
        "        return option1()\n",
        "    else:\n",
        "        return option2()\n",
        "\n",
        "\n",
        "def synthesise_address(*record) -> (int, np.ndarray, np.ndarray):\n",
        "    \"\"\"\n",
        "    Uses the record information to construct a formatted address with labels. The addresses generated involve\n",
        "    semi-random permutations and corruptions to help avoid over-fitting.\n",
        "    :param record: the decoded item from the TFRecord file\n",
        "    :return: the address string length, encoded text and labels\n",
        "    \"\"\"\n",
        "    fields = dict(zip(_features.keys(), decode_data(record)))\n",
        "\n",
        "    # Generate the individual address components:\n",
        "    if fields['level_type'] > 0:\n",
        "        level = generate_level_number(fields['level_type'], fields['level_number_prefix'], fields['level_number'],\n",
        "                                      fields['level_number_suffix'])\n",
        "    else:\n",
        "        level = ('', np.zeros((0, n_labels)))\n",
        "\n",
        "    if fields['flat_type'] > 0:\n",
        "        flat_number = generate_flat_number(\n",
        "            fields['flat_type'], fields['flat_number_prefix'], fields['flat_number'], fields['flat_number_suffix'])\n",
        "    else:\n",
        "        flat_number = ('', np.zeros((0, n_labels)))\n",
        "\n",
        "    street_number = generate_street_number(fields['number_first_prefix'], fields['number_first'],\n",
        "                                           fields['number_first_suffix'], fields['number_last_prefix'],\n",
        "                                           fields['number_last'], fields['number_last_suffix'])\n",
        "    street = generate_street_name(fields['street_name'], fields['street_suffix_code'], fields['street_type_code'])\n",
        "    suburb = labels(fields['locality_name'], 'locality_name')\n",
        "    state = generate_state(fields['state_abbreviation'])\n",
        "    postcode = labels(fields['postcode'], 'postcode')\n",
        "    building_name = labels(fields['building_name'], 'building_name')\n",
        "\n",
        "    # Begin composing the formatted address, building up the `parts` variable...\n",
        "\n",
        "    suburb_state_postcode = list()\n",
        "    # Keep the suburb?\n",
        "    choose(lambda: suburb_state_postcode.append(suburb))\n",
        "    # Keep state?\n",
        "    choose(lambda: suburb_state_postcode.append(state))\n",
        "    # Keep postcode?\n",
        "    choose(lambda: suburb_state_postcode.append(postcode))\n",
        "\n",
        "    random.shuffle(suburb_state_postcode)\n",
        "\n",
        "    parts = [[building_name], [level]]\n",
        "\n",
        "    # Keep the street number? (If street number is dropped, the flat number is also dropped)\n",
        "    def keep_street_number():\n",
        "        # force flat number to be next to street number only if the flat number is only digits (i.e. does not have a\n",
        "        # flat type)\n",
        "        if flat_number[0].isdigit():\n",
        "            parts.append([flat_number, street_number, street])\n",
        "        else:\n",
        "            parts.append([flat_number])\n",
        "            parts.append([street_number, street])\n",
        "\n",
        "    choose(keep_street_number, lambda: parts.append([street]))\n",
        "\n",
        "    random.shuffle(parts)\n",
        "\n",
        "    # Suburb, state, postcode is always at the end of an address\n",
        "    parts.append(suburb_state_postcode)\n",
        "\n",
        "    # Flatten the address components into an unnested list\n",
        "    parts = sum(parts, [])\n",
        "\n",
        "    # Join each address component/label with a random separator\n",
        "    address, address_lbl = join_str_and_labels(parts, sep=lambda: random_separator(1, 3))\n",
        "\n",
        "    # Encode\n",
        "    length, text_encoded = vocab_lookup(address)\n",
        "    return length, text_encoded, address_lbl\n",
        "\n",
        "\n",
        "def generate_state(state_abbreviation: int) -> (str, np.ndarray):\n",
        "    \"\"\"\n",
        "    Generates the string and labels for the state, randomly abbreviated\n",
        "    :param state_abbreviation: the state code\n",
        "    :return: string and labels\n",
        "    \"\"\"\n",
        "    state = lookups.lookup_state(state_abbreviation, reverse_lookup=True)\n",
        "    return labels(choose(lambda: lookups.expand_state(state), lambda: state), 'state_abbreviation')\n",
        "\n",
        "\n",
        "def generate_level_number(level_type: int, level_number_prefix: str, level_number: int, level_number_suffix: str) -> (\n",
        "        str, np.ndarray):\n",
        "    \"\"\"\n",
        "    Generates the level number for the address\n",
        "    :param level_type: level type code\n",
        "    :param level_number_prefix: number prefix\n",
        "    :param level_number: level number\n",
        "    :param level_number_suffix: level number suffix\n",
        "    :return: string and labels\n",
        "    \"\"\"\n",
        "\n",
        "    level_type = labels(lookups.lookup_level_type(level_type, reverse_lookup=True), 'level_type')\n",
        "\n",
        "    # Decide whether to transform the level number\n",
        "    def do_transformation():\n",
        "        if not level_number_prefix and not level_number_suffix and level_type[0]:\n",
        "            # If there is no prefix/suffix, decide whether to convert to ordinal numbers (1st, 2nd, etc.)\n",
        "            def use_ordinal_numbers(lvl_num, lvl_type):\n",
        "                # Use ordinal words (first, second, third) or numbers (1st, 2nd, 3rd)?\n",
        "                lvl_num = choose(lambda: lookups.num2word(lvl_num, output='ordinal_words'),\n",
        "                                 lambda: lookups.num2word(lvl_num, output='ordinal'))\n",
        "                lvl_num = labels(lvl_num, 'level_number')\n",
        "                return join_str_and_labels([lvl_num, lvl_type],\n",
        "                                           sep=lambda: random_separator(1, 3, possible_sep_chars=None))\n",
        "\n",
        "            def use_cardinal_numbers(lvl_num, lvl_type):\n",
        "                # Treat level 1 as GROUND?\n",
        "                if lvl_num == 1:\n",
        "                    lvl_num = choose(lambda: \"GROUND\", lambda: 1)\n",
        "                else:\n",
        "                    lvl_num = lookups.num2word(lvl_num, output='cardinal')\n",
        "                lvl_num = labels(lvl_num, 'level_number')\n",
        "                return join_str_and_labels([lvl_type, lvl_num],\n",
        "                                           sep=lambda: random_separator(1, 3, possible_sep_chars=None))\n",
        "\n",
        "            return choose(lambda: use_ordinal_numbers(level_number, level_type),\n",
        "                          lambda: use_cardinal_numbers(level_number, level_type))\n",
        "\n",
        "    transformed_value = choose(do_transformation)\n",
        "    if transformed_value:\n",
        "        return transformed_value\n",
        "    else:\n",
        "        level_number_prefix = labels(level_number_prefix, 'level_number_prefix')\n",
        "        level_number = labels(level_number, 'level_number')\n",
        "        level_number_suffix = labels(level_number_suffix, 'level_number_suffix')\n",
        "        return join_str_and_labels([level_type, level_number_prefix, level_number, level_number_suffix],\n",
        "                                   sep=lambda: random_separator(1, 3, possible_sep_chars=None))\n",
        "\n",
        "\n",
        "def generate_flat_number(\n",
        "        flat_type: int, flat_number_prefix: str, flat_number: int, flat_number_suffix: str) -> (str, np.ndarray):\n",
        "    \"\"\"\n",
        "    Generates the flat number for the address\n",
        "    :param flat_type: flat type code\n",
        "    :param flat_number_prefix: number prefix\n",
        "    :param flat_number: number\n",
        "    :param flat_number_suffix: number suffix\n",
        "    :return: string and labels\n",
        "    \"\"\"\n",
        "    flat_type = labels(lookups.lookup_flat_type(flat_type, reverse_lookup=True), 'flat_type')\n",
        "    flat_number_prefix = labels(flat_number_prefix, 'flat_number_prefix')\n",
        "    flat_number = labels(flat_number, 'flat_number')\n",
        "    flat_number_suffix = labels(flat_number_suffix, 'flat_number_suffix')\n",
        "\n",
        "    flat_number = join_str_and_labels([flat_number_prefix, flat_number, flat_number_suffix],\n",
        "                                      sep=lambda: random_separator(0, 2, possible_sep_chars=None))\n",
        "\n",
        "    return choose(\n",
        "        lambda: join_str_and_labels([flat_type, flat_number], sep=random_separator(0, 2, possible_sep_chars=None)),\n",
        "        lambda: flat_number)\n",
        "\n",
        "\n",
        "def generate_street_number(number_first_prefix: str, number_first: int, number_first_suffix,\n",
        "                           number_last_prefix, number_last, number_last_suffix) -> (str, np.ndarray):\n",
        "    \"\"\"\n",
        "    Generates a street number using the prefix, suffix, first and last number components\n",
        "    :param number_first_prefix: prefix to the first street number\n",
        "    :param number_first: first street number\n",
        "    :param number_first_suffix: suffix to the first street number\n",
        "    :param number_last_prefix: prefix to the last street number\n",
        "    :param number_last: last street number\n",
        "    :param number_last_suffix: suffix to the last street number\n",
        "    :return: the street number\n",
        "    \"\"\"\n",
        "\n",
        "    number_first_prefix = labels(number_first_prefix, 'number_first_prefix')\n",
        "    number_first = labels(number_first, 'number_first')\n",
        "    number_first_suffix = labels(number_first_suffix, 'number_first_suffix')\n",
        "\n",
        "    number_last_prefix = labels(number_last_prefix, 'number_last_prefix')\n",
        "    number_last = labels(number_last, 'number_last')\n",
        "    number_last_suffix = labels(number_last_suffix, 'number_last_suffix')\n",
        "\n",
        "    a = join_str_and_labels([number_first_prefix, number_first, number_first_suffix],\n",
        "                            lambda: random_separator(0, 2, possible_sep_chars=None))\n",
        "    b = join_str_and_labels([number_last_prefix, number_last, number_last_suffix],\n",
        "                            lambda: random_separator(0, 2, possible_sep_chars=None))\n",
        "\n",
        "    return join_str_and_labels([a, b], sep=random_separator(1, 3, possible_sep_chars=r\"----   \\/\"))\n",
        "\n",
        "\n",
        "def generate_street_name(street_name: str, street_suffix_code: str, street_type_code: str) -> (str, np.ndarray):\n",
        "    \"\"\"\n",
        "    Generates a possible street name variation\n",
        "    :param street_name: the street's name\n",
        "    :param street_suffix_code: the street suffix code\n",
        "    :param street_type_code: the street type code\n",
        "    :return: string and labels\n",
        "    \"\"\"\n",
        "    street_name, street_name_lbl = labels(street_name, 'street_name')\n",
        "\n",
        "    street_type = lookups.lookup_street_type(street_type_code, reverse_lookup=True)\n",
        "    street_type = choose(lambda: lookups.abbreviate_street_type(street_type), lambda: street_type)\n",
        "    street_type, street_type_lbl = labels(street_type, 'street_type_code')\n",
        "\n",
        "    street_suffix = lookups.lookup_street_suffix(street_suffix_code, reverse_lookup=True)\n",
        "    street_suffix = choose(lambda: lookups.expand_street_type_suffix(street_suffix), lambda: street_suffix)\n",
        "    street_suffix, street_suffix_lbl = labels(street_suffix, 'street_suffix_code')\n",
        "\n",
        "    return choose(lambda: join_str_and_labels([\n",
        "        (street_name, street_name_lbl),\n",
        "        (street_suffix, street_suffix_lbl),\n",
        "        (street_type, street_type_lbl)\n",
        "    ]), lambda: join_str_and_labels([\n",
        "        (street_name, street_name_lbl),\n",
        "        (street_type, street_type_lbl),\n",
        "        (street_suffix, street_suffix_lbl)\n",
        "    ]))\n",
        "\n",
        "\n",
        "def dataset(filenames: [str], batch_size: int = 10, shuffle_buffer: int = 1000, prefetch_buffer_size: int = 10000,\n",
        "            num_parallel_calls: int = 8) -> Callable:\n",
        "    \"\"\"\n",
        "    Creates a Tensorflow dataset and iterator operations\n",
        "    :param filenames: the tfrecord filenames\n",
        "    :param batch_size: training batch size\n",
        "    :param shuffle_buffer: shuffle buffer size\n",
        "    :param prefetch_buffer_size: size of the prefetch buffer\n",
        "    :param num_parallel_calls: number of parallel calls for the mapping functions\n",
        "    :return: the input_fn\n",
        "    \"\"\"\n",
        "\n",
        "    def input_fn() -> tf.data.Dataset:\n",
        "        ds = tf.data.TFRecordDataset(filenames, compression_type=\"GZIP\")\n",
        "        ds = ds.shuffle(buffer_size=shuffle_buffer)\n",
        "        ds = ds.map(lambda record: tf.parse_single_example(record, features=_features), num_parallel_calls=8)\n",
        "        ds = ds.map(\n",
        "            lambda record: tf.py_func(synthesise_address, [record[k] for k in _features.keys()],\n",
        "                                      [tf.int64, tf.int64, tf.bool],\n",
        "                                      stateful=False),\n",
        "            num_parallel_calls=num_parallel_calls\n",
        "        )\n",
        "\n",
        "        ds = ds.padded_batch(batch_size, ([], [None], [None, n_labels]))\n",
        "\n",
        "        ds = ds.map(\n",
        "            lambda _lengths, _encoded_text, _labels: ({'lengths': _lengths, 'encoded_text': _encoded_text}, _labels),\n",
        "            num_parallel_calls=num_parallel_calls\n",
        "        )\n",
        "        ds = ds.prefetch(buffer_size=prefetch_buffer_size)\n",
        "        return ds\n",
        "\n",
        "    return input_fn\n",
        "\n",
        "\n",
        "def predict_input_fn(input_text: List[str]) -> Callable:\n",
        "    \"\"\"\n",
        "    An input function for one prediction example\n",
        "    :param input_text: the input text\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    def input_fn() -> tf.data.Dataset:\n",
        "        predict_ds = tf.data.Dataset.from_generator(\n",
        "            lambda: (vocab_lookup(address) for address in input_text),\n",
        "            (tf.int64, tf.int64),\n",
        "            (tf.TensorShape([]), tf.TensorShape([None]))\n",
        "        )\n",
        "        predict_ds = predict_ds.batch(1)\n",
        "        predict_ds = predict_ds.map(\n",
        "            lambda lengths, encoded_text: {'lengths': lengths, 'encoded_text': encoded_text}\n",
        "        )\n",
        "        return predict_ds\n",
        "\n",
        "    return input_fn"
      ],
      "metadata": {
        "id": "Uca6BFCW1G0A"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "from typing import Union\n",
        "\n",
        "# Categorical types as per the GNAF dataset, see: https://data.gov.au/dataset/geocoded-national-address-file-g-naf\n",
        "flat_types = ('ANTENNA', 'APARTMENT', 'AUTOMATED TELLER MACHINE', 'BARBECUE', 'BLOCK', 'BOATSHED', 'BUILDING',\n",
        "              'BUNGALOW', 'CAGE', 'CARPARK', 'CARSPACE', 'CLUB', 'COOLROOM', 'COTTAGE', 'DUPLEX', 'FACTORY', 'FLAT',\n",
        "              'GARAGE', 'HALL', 'HOUSE', 'KIOSK', 'LEASE', 'LOBBY', 'LOFT', 'LOT', 'MAISONETTE', 'MARINE BERTH',\n",
        "              'OFFICE', 'PENTHOUSE', 'REAR', 'RESERVE', 'ROOM', 'SECTION', 'SHED', 'SHOP', 'SHOWROOM', 'SIGN', 'SITE',\n",
        "              'STALL', 'STORE', 'STRATA UNIT', 'STUDIO', 'SUBSTATION', 'SUITE', 'TENANCY', 'TOWER', 'TOWNHOUSE',\n",
        "              'UNIT', 'VAULT', 'VILLA', 'WARD', 'WAREHOUSE', 'WORKSHOP')\n",
        "\n",
        "level_types = ('BASEMENT', 'FLOOR', 'GROUND', 'LEVEL', 'LOBBY', 'LOWER GROUND FLOOR', 'MEZZANINE', 'OBSERVATION DECK',\n",
        "               'PARKING', 'PENTHOUSE', 'PLATFORM', 'PODIUM', 'ROOFTOP', 'SUB-BASEMENT', 'UPPER GROUND FLOOR')\n",
        "\n",
        "street_types = ('ACCESS', 'ACRE', 'AIRWALK', 'ALLEY', 'ALLEYWAY', 'AMBLE', 'APPROACH', 'ARCADE', 'ARTERIAL', 'ARTERY',\n",
        "                'AVENUE', 'BANAN', 'BANK', 'BAY', 'BEACH', 'BEND', 'BOARDWALK', 'BOULEVARD', 'BOULEVARDE', 'BOWL',\n",
        "                'BRACE', 'BRAE', 'BRANCH', 'BREAK', 'BRETT', 'BRIDGE', 'BROADWALK', 'BROADWAY', 'BROW', 'BULL',\n",
        "                'BUSWAY', 'BYPASS', 'BYWAY', 'CAUSEWAY', 'CENTRE', 'CENTREWAY', 'CHASE', 'CIRCLE', 'CIRCLET',\n",
        "                'CIRCUIT', 'CIRCUS', 'CLOSE', 'CLUSTER', 'COLONNADE', 'COMMON', 'COMMONS', 'CONCORD', 'CONCOURSE',\n",
        "                'CONNECTION', 'COPSE', 'CORNER', 'CORSO', 'COURSE', 'COURT', 'COURTYARD', 'COVE', 'CRESCENT', 'CREST',\n",
        "                'CRIEF', 'CROOK', 'CROSS', 'CROSSING', 'CRUISEWAY', 'CUL-DE-SAC', 'CUT', 'CUTTING', 'DALE', 'DASH',\n",
        "                'DELL', 'DENE', 'DEVIATION', 'DIP', 'DISTRIBUTOR', 'DIVIDE', 'DOCK', 'DOMAIN', 'DOWN', 'DOWNS',\n",
        "                'DRIVE', 'DRIVEWAY', 'EASEMENT', 'EAST', 'EDGE', 'ELBOW', 'END', 'ENTRANCE', 'ESPLANADE', 'ESTATE',\n",
        "                'EXPRESSWAY', 'EXTENSION', 'FAIRWAY', 'FIREBREAK', 'FIRELINE', 'FIRETRACK', 'FIRETRAIL', 'FLAT',\n",
        "                'FLATS', 'FOLLOW', 'FOOTWAY', 'FORD', 'FORESHORE', 'FORK', 'FORMATION', 'FREEWAY', 'FRONT', 'FRONTAGE',\n",
        "                'GAP', 'GARDEN', 'GARDENS', 'GATE', 'GATEWAY', 'GLADE', 'GLEN', 'GRANGE', 'GREEN', 'GROVE', 'GULLY',\n",
        "                'HARBOUR', 'HAVEN', 'HEATH', 'HEIGHTS', 'HIGHROAD', 'HIGHWAY', 'HIKE', 'HILL', 'HILLS', 'HOLLOW',\n",
        "                'HUB', 'INLET', 'INTERCHANGE', 'ISLAND', 'JUNCTION', 'KEY', 'KEYS', 'KNOLL', 'LADDER', 'LANDING',\n",
        "                'LANE', 'LANEWAY', 'LEAD', 'LEADER', 'LINE', 'LINK', 'LOOKOUT', 'LOOP', 'LYNNE', 'MALL', 'MANOR',\n",
        "                'MART', 'MAZE', 'MEAD', 'MEANDER', 'MEW', 'MEWS', 'MILE', 'MOTORWAY', 'NOOK', 'NORTH', 'NULL',\n",
        "                'OUTLET', 'OUTLOOK', 'OVAL', 'PALMS', 'PARADE', 'PARADISE', 'PARK', 'PARKWAY', 'PART', 'PASS',\n",
        "                'PASSAGE', 'PATH', 'PATHWAY', 'PENINSULA', 'PIAZZA', 'PLACE', 'PLAZA', 'POCKET', 'POINT', 'PORT',\n",
        "                'PRECINCT', 'PROMENADE', 'PURSUIT', 'QUAD', 'QUADRANT', 'QUAY', 'QUAYS', 'RAMBLE', 'RAMP', 'RANGE',\n",
        "                'REACH', 'REEF', 'RESERVE', 'REST', 'RETREAT', 'RETURN', 'RIDE', 'RIDGE', 'RIGHT OF WAY', 'RING',\n",
        "                'RISE', 'RISING', 'RIVER', 'ROAD', 'ROADS', 'ROADWAY', 'ROTARY', 'ROUND', 'ROUTE', 'ROW', 'ROWE',\n",
        "                'RUE', 'RUN', 'SERVICEWAY', 'SHUNT', 'SKYLINE', 'SLOPE', 'SOUTH', 'SPUR', 'SQUARE', 'STEPS',\n",
        "                'STRAIGHT', 'STRAIT', 'STRAND', 'STREET', 'STRIP', 'SUBWAY', 'TARN', 'TERRACE', 'THOROUGHFARE',\n",
        "                'THROUGHWAY', 'TOLLWAY', 'TOP', 'TOR', 'TRACK', 'TRAIL', 'TRAMWAY', 'TRAVERSE', 'TRIANGLE', 'TRUNKWAY',\n",
        "                'TUNNEL', 'TURN', 'TWIST', 'UNDERPASS', 'VALE', 'VALLEY', 'VERGE', 'VIADUCT', 'VIEW', 'VIEWS', 'VILLA',\n",
        "                'VILLAGE', 'VILLAS', 'VISTA', 'VUE', 'WADE', 'WALK', 'WALKWAY', 'WATERS', 'WATERWAY', 'WAY', 'WEST',\n",
        "                'WHARF', 'WOOD', 'WOODS', 'WYND', 'YARD')\n",
        "\n",
        "street_suffix_types = OrderedDict([('CN', 'CENTRAL'), ('DE', 'DEVIATION'), ('E', 'EAST'), ('EX', 'EXTENSION'),\n",
        "                                   ('IN', 'INNER'), ('LR', 'LOWER'), ('ML', 'MALL'), ('N', 'NORTH'),\n",
        "                                   ('NE', 'NORTH EAST'), ('NW', 'NORTH WEST'), ('OF', 'OFF'), ('ON', 'ON'),\n",
        "                                   ('OT', 'OUTER'), ('OP', 'OVERPASS'), ('S', 'SOUTH'), ('SE', 'SOUTH EAST'),\n",
        "                                   ('SW', 'SOUTH WEST'), ('UP', 'UPPER'), ('W', 'WEST')])\n",
        "\n",
        "states = OrderedDict([('ACT', 'AUSTRALIAN CAPITAL TERRITORY'), ('NSW', 'NEW SOUTH WALES'),\n",
        "                      ('NT', 'NORTHERN TERRITORY'), ('OT', 'OTHER TERRITORIES'), ('QLD', 'QUEENSLAND'),\n",
        "                      ('SA', 'SOUTH AUSTRALIA'), ('TAS', 'TASMANIA'), ('VIC', 'VICTORIA'),\n",
        "                      ('WA', 'WESTERN AUSTRALIA')])\n",
        "\n",
        "# Abbreviaitons from METeOR identifier: 429387\n",
        "# see https://meteor.aihw.gov.au/content/index.phtml/itemId/429387/pageDefinitionItemId/tag.MeteorPrinterFriendlyPage\n",
        "street_type_abbreviation = {'ACCESS': 'ACCS', 'ALLEY': 'ALLY', 'ALLEYWAY': 'ALWY', 'AMBLE': 'AMBL', 'APPROACH': 'APP',\n",
        "                            'ARCADE': 'ARC', 'ARTERIAL': 'ARTL', 'ARTERY': 'ARTY', 'AVENUE': 'AV', 'BANAN': 'BA',\n",
        "                            'BEND': 'BEND', 'BOARDWALK': 'BWLK', 'BOULEVARD': 'BVD', 'BRACE': 'BR', 'BRAE': 'BRAE',\n",
        "                            'BREAK': 'BRK', 'BROW': 'BROW', 'BYPASS': 'BYPA', 'BYWAY': 'BYWY', 'CAUSEWAY': 'CSWY',\n",
        "                            'CENTRE': 'CTR', 'CHASE': 'CH', 'CIRCLE': 'CIR', 'CIRCUIT': 'CCT', 'CIRCUS': 'CRCS',\n",
        "                            'CLOSE': 'CL', 'CONCOURSE': 'CON', 'COPSE': 'CPS', 'CORNER': 'CNR', 'COURT': 'CT',\n",
        "                            'COURTYARD': 'CTYD', 'COVE': 'COVE', 'CRESCENT': 'CR', 'CREST': 'CRST', 'CROSS': 'CRSS',\n",
        "                            'CUL-DE-SAC': 'CSAC', 'CUTTING': 'CUTT', 'DALE': 'DALE', 'DIP': 'DIP', 'DRIVE': 'DR',\n",
        "                            'DRIVEWAY': 'DVWY', 'EDGE': 'EDGE', 'ELBOW': 'ELB', 'END': 'END', 'ENTRANCE': 'ENT',\n",
        "                            'ESPLANADE': 'ESP', 'EXPRESSWAY': 'EXP', 'FAIRWAY': 'FAWY', 'FOLLOW': 'FOLW',\n",
        "                            'FOOTWAY': 'FTWY', 'FORMATION': 'FORM', 'FREEWAY': 'FWY', 'FRONTAGE': 'FRTG',\n",
        "                            'GAP': 'GAP', 'GARDENS': 'GDNS', 'GATE': 'GTE', 'GLADE': 'GLDE', 'GLEN': 'GLEN',\n",
        "                            'GRANGE': 'GRA', 'GREEN': 'GRN', 'GROVE': 'GR', 'HEIGHTS': 'HTS', 'HIGHROAD': 'HIRD',\n",
        "                            'HIGHWAY': 'HWY', 'HILL': 'HILL', 'INTERCHANGE': 'INTG', 'JUNCTION': 'JNC', 'KEY': 'KEY',\n",
        "                            'LANE': 'LANE', 'LANEWAY': 'LNWY', 'LINE': 'LINE', 'LINK': 'LINK', 'LOOKOUT': 'LKT',\n",
        "                            'LOOP': 'LOOP', 'MALL': 'MALL', 'MEANDER': 'MNDR', 'MEWS': 'MEWS', 'MOTORWAY': 'MTWY',\n",
        "                            'NOOK': 'NOOK', 'OUTLOOK': 'OTLK', 'PARADE': 'PDE', 'PARKWAY': 'PWY', 'PASS': 'PASS',\n",
        "                            'PASSAGE': 'PSGE', 'PATH': 'PATH', 'PATHWAY': 'PWAY', 'PIAZZA': 'PIAZ', 'PLAZA': 'PLZA',\n",
        "                            'POCKET': 'PKT', 'POINT': 'PNT', 'PORT': 'PORT', 'PROMENADE': 'PROM', 'QUADRANT': 'QDRT',\n",
        "                            'QUAYS': 'QYS', 'RAMBLE': 'RMBL', 'REST': 'REST', 'RETREAT': 'RTT', 'RIDGE': 'RDGE',\n",
        "                            'RISE': 'RISE', 'ROAD': 'RD', 'ROTARY': 'RTY', 'ROUTE': 'RTE', 'ROW': 'ROW', 'RUE': 'RUE',\n",
        "                            'SERVICEWAY': 'SVWY', 'SHUNT': 'SHUN', 'SPUR': 'SPUR', 'SQUARE': 'SQ', 'STREET': 'ST',\n",
        "                            'SUBWAY': 'SBWY', 'TARN': 'TARN', 'TERRACE': 'TCE', 'THOROUGHFARE': 'THFR',\n",
        "                            'TOLLWAY': 'TLWY', 'TOP': 'TOP', 'TOR': 'TOR', 'TRACK': 'TRK', 'TRAIL': 'TRL',\n",
        "                            'TURN': 'TURN', 'UNDERPASS': 'UPAS', 'VALE': 'VALE', 'VIADUCT': 'VIAD', 'VIEW': 'VIEW',\n",
        "                            'VISTA': 'VSTA', 'WALK': 'WALK', 'WALKWAY': 'WKWY', 'WHARF': 'WHRF', 'WYND': 'WYND'}\n",
        "\n",
        "ordinal_words = [\n",
        "    'first', 'second', 'third', 'fourth', 'fifth', 'sixth', 'seventh', 'eighth', 'ninth', 'tenth', 'eleventh',\n",
        "    'twelfth', 'thirteenth', 'fourteenth', 'fifteenth', 'sixteenth', 'seventeenth', 'eighteenth', 'nineteenth',\n",
        "    'twentieth', 'twenty-first', 'twenty-second', 'twenty-third', 'twenty-fourth', 'twenty-fifth', 'twenty-sixth',\n",
        "    'twenty-seventh', 'twenty-eighth', 'twenty-ninth', 'thirtieth', 'thirty-first', 'thirty-second', 'thirty-third',\n",
        "    'thirty-fourth', 'thirty-fifth', 'thirty-sixth', 'thirty-seventh', 'thirty-eighth', 'thirty-ninth', 'fortieth',\n",
        "    'forty-first', 'forty-second', 'forty-third', 'forty-fourth', 'forty-fifth', 'forty-sixth', 'forty-seventh',\n",
        "    'forty-eighth', 'forty-ninth', 'fiftieth', 'fifty-first', 'fifty-second', 'fifty-third', 'fifty-fourth',\n",
        "    'fifty-fifth', 'fifty-sixth', 'fifty-seventh', 'fifty-eighth', 'fifty-ninth', 'sixtieth', 'sixty-first',\n",
        "    'sixty-second', 'sixty-third', 'sixty-fourth', 'sixty-fifth', 'sixty-sixth', 'sixty-seventh', 'sixty-eighth',\n",
        "    'sixty-ninth', 'seventieth', 'seventy-first', 'seventy-second', 'seventy-third', 'seventy-fourth', 'seventy-fifth',\n",
        "    'seventy-sixth', 'seventy-seventh', 'seventy-eighth', 'seventy-ninth', 'eightieth', 'eighty-first', 'eighty-second',\n",
        "    'eighty-third', 'eighty-fourth', 'eighty-fifth', 'eighty-sixth', 'eighty-seventh', 'eighty-eighth', 'eighty-ninth',\n",
        "    'ninetieth', 'ninety-first', 'ninety-second', 'ninety-third', 'ninety-fourth', 'ninety-fifth', 'ninety-sixth',\n",
        "    'ninety-seventh', 'ninety-eighth', 'ninety-ninth', 'one hundredth'\n",
        "]\n",
        "\n",
        "cardinal_words = [\n",
        "    'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', 'thirteen',\n",
        "    'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen', 'twenty', 'twenty-one', 'twenty-two',\n",
        "    'twenty-three', 'twenty-four', 'twenty-five', 'twenty-six', 'twenty-seven', 'twenty-eight', 'twenty-nine', 'thirty',\n",
        "    'thirty-one', 'thirty-two', 'thirty-three', 'thirty-four', 'thirty-five', 'thirty-six', 'thirty-seven',\n",
        "    'thirty-eight', 'thirty-nine', 'forty', 'forty-one', 'forty-two', 'forty-three', 'forty-four', 'forty-five',\n",
        "    'forty-six', 'forty-seven', 'forty-eight', 'forty-nine', 'fifty', 'fifty-one', 'fifty-two', 'fifty-three',\n",
        "    'fifty-four', 'fifty-five', 'fifty-six', 'fifty-seven', 'fifty-eight', 'fifty-nine', 'sixty', 'sixty-one',\n",
        "    'sixty-two', 'sixty-three', 'sixty-four', 'sixty-five', 'sixty-six', 'sixty-seven', 'sixty-eight', 'sixty-nine',\n",
        "    'seventy', 'seventy-one', 'seventy-two', 'seventy-three', 'seventy-four', 'seventy-five', 'seventy-six',\n",
        "    'seventy-seven', 'seventy-eight', 'seventy-nine', 'eighty', 'eighty-one', 'eighty-two', 'eighty-three',\n",
        "    'eighty-four', 'eighty-five', 'eighty-six', 'eighty-seven', 'eighty-eight', 'eighty-nine', 'ninety', 'ninety-one',\n",
        "    'ninety-two', 'ninety-three', 'ninety-four', 'ninety-five', 'ninety-six', 'ninety-seven', 'ninety-eight',\n",
        "    'ninety-nine', 'one hundred'\n",
        "]\n",
        "\n",
        "\n",
        "def _lookup(t: str, types: [str]) -> int:\n",
        "    \"\"\"\n",
        "    Looks up the value, t, from the array of types\n",
        "    :param t: value to lookup\n",
        "    :param types: list of types from which to lookup\n",
        "    :return: an integer value > 0 if found, or 0 if not found\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return types.index(t.strip().upper()) + 1\n",
        "    except ValueError:\n",
        "        return 0\n",
        "\n",
        "\n",
        "def _reverse_lookup(idx: int, types: [str]) -> str:\n",
        "    \"\"\"\n",
        "    Converts an integer value back to the string representation\n",
        "    :param idx: integer value\n",
        "    :param types: list of types\n",
        "    :return: the string value or None if not found (idx == 0)\n",
        "    \"\"\"\n",
        "    if idx == 0:\n",
        "        return ''\n",
        "    else:\n",
        "        return types[idx - 1]\n",
        "\n",
        "\n",
        "def lookup_state(state: Union[str, int], reverse_lookup=False) -> Union[str, int]:\n",
        "    \"\"\"\n",
        "    Converts the representation for the geographic state\n",
        "    :param state: string or int to lookup\n",
        "    :param reverse_lookup: True if converting int to string, or False if string to int\n",
        "    :return: the encoded value\n",
        "    \"\"\"\n",
        "    if reverse_lookup:\n",
        "        return _reverse_lookup(state, list(states.keys()))\n",
        "    return _lookup(state, list(states.keys()))\n",
        "\n",
        "\n",
        "def expand_state(state: str) -> str:\n",
        "    \"\"\"\n",
        "    Converts an abbreviated state name to the full name, e.g. \"VIC\" -> \"VICTORIA\"\n",
        "    :param state: abbreviated state\n",
        "    :return: full state\n",
        "    \"\"\"\n",
        "    return states[state.strip().upper()]\n",
        "\n",
        "\n",
        "def lookup_street_type(street_type: Union[str, int], reverse_lookup=False) -> Union[str, int]:\n",
        "    \"\"\"\n",
        "    Converts the representation for the street type\n",
        "    :param street_type: string or int to lookup\n",
        "    :param reverse_lookup: True if converting int to string, or False if string to int\n",
        "    :return: the encoded value\n",
        "    \"\"\"\n",
        "    if reverse_lookup:\n",
        "        return _reverse_lookup(street_type, street_types)\n",
        "    return _lookup(street_type, street_types)\n",
        "\n",
        "\n",
        "def abbreviate_street_type(street_type: str) -> str:\n",
        "    \"\"\"\n",
        "    Converts an full street type to the abbreviated name, e.g. \"STREET\" -> \"ST\"\n",
        "    :param street_type: full street type\n",
        "    :return: abbreviated street type\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return street_type_abbreviation[street_type.strip().upper()]\n",
        "    except KeyError:\n",
        "        return street_type\n",
        "\n",
        "\n",
        "def lookup_street_suffix(street_suffix: Union[str, int], reverse_lookup=False) -> Union[str, int]:\n",
        "    \"\"\"\n",
        "    Converts the representation for the street type suffix\n",
        "    :param street_suffix: string or int to lookup\n",
        "    :param reverse_lookup: True if converting int to string, or False if string to int\n",
        "    :return: the encoded value\n",
        "    \"\"\"\n",
        "    if reverse_lookup:\n",
        "        return _reverse_lookup(street_suffix, list(street_suffix_types.keys()))\n",
        "    return _lookup(street_suffix, list(street_suffix_types.keys()))\n",
        "\n",
        "\n",
        "def expand_street_type_suffix(street_suffix: str) -> str:\n",
        "    \"\"\"\n",
        "    Converts an abbreviated street suffix to the full name, e.g. \"N\" -> \"NORTH\"\n",
        "    :param street_suffix: abbreviated street suffix\n",
        "    :return: full street suffix\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return street_suffix_types[street_suffix.strip().upper()]\n",
        "    except KeyError:\n",
        "        return street_suffix\n",
        "\n",
        "\n",
        "def lookup_level_type(level_type: Union[str, int], reverse_lookup=False) -> Union[str, int]:\n",
        "    \"\"\"\n",
        "    Converts the representation for the level type\n",
        "    :param level_type: string or int to lookup\n",
        "    :param reverse_lookup: True if converting int to string, or False if string to int\n",
        "    :return: the encoded value\n",
        "    \"\"\"\n",
        "    if reverse_lookup:\n",
        "        return _reverse_lookup(level_type, level_types)\n",
        "    return _lookup(level_type, level_types)\n",
        "\n",
        "\n",
        "def lookup_flat_type(flat_type: Union[str, int], reverse_lookup=False) -> Union[str, int]:\n",
        "    \"\"\"\n",
        "    Converts the representation for the flat type\n",
        "    :param flat_type: string or int to lookup\n",
        "    :param reverse_lookup: True if converting int to string, or False if string to int\n",
        "    :return: the encoded value\n",
        "    \"\"\"\n",
        "    if reverse_lookup:\n",
        "        return _reverse_lookup(flat_type, flat_types)\n",
        "    return _lookup(flat_type, flat_types)\n",
        "\n",
        "\n",
        "# Adapted from http://code.activestate.com/recipes/576888-format-a-number-as-an-ordinal/\n",
        "def num2word(value, output='ordinal_words'):\n",
        "    \"\"\"\n",
        "    Converts zero or a *postive* integer (or their string\n",
        "    representations) to an ordinal/cardinal value.\n",
        "    :param value: the number to convert\n",
        "    :param output: one of 'ordinal_words', 'ordinal', 'cardinal'\n",
        "    \"\"\"\n",
        "    try:\n",
        "        value = int(value)\n",
        "    except ValueError:\n",
        "        return value\n",
        "\n",
        "    assert output in (\n",
        "    'ordinal_words', 'ordinal', 'cardinal'), \"`output` must be one of 'ordinal_words', 'ordinal' or 'cardinal'\"\n",
        "\n",
        "    if output == 'ordinal_words' and (0 < value < 100):\n",
        "        val = ordinal_words[value - 1]\n",
        "    elif output == 'ordinal_words':\n",
        "        raise ValueError(\"'ordinal_words' only supported between 1 and 100\")\n",
        "    elif output == 'ordinal':\n",
        "        if value % 100 // 10 != 1:\n",
        "            if value % 10 == 1:\n",
        "                val = u\"%d%s\" % (value, \"st\")\n",
        "            elif value % 10 == 2:\n",
        "                val = u\"%d%s\" % (value, \"nd\")\n",
        "            elif value % 10 == 3:\n",
        "                val = u\"%d%s\" % (value, \"rd\")\n",
        "            else:\n",
        "                val = u\"%d%s\" % (value, \"th\")\n",
        "        else:\n",
        "            val = u\"%d%s\" % (value, \"th\")\n",
        "    else:\n",
        "        val = cardinal_words[value - 1]\n",
        "\n",
        "    return val.upper()"
      ],
      "metadata": {
        "id": "6v_XtJgq0H-E"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, Optional\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from addressnet.dataset import vocab, n_labels\n",
        "\n",
        "\n",
        "def model_fn(features: Dict[str, tf.Tensor], labels: tf.Tensor, mode: str, params) -> tf.estimator.EstimatorSpec:\n",
        "    \"\"\"\n",
        "    The AddressNet model function suitable for tf.estimator.Estimator\n",
        "    :param features: a dictionary containing tensors for the encoded_text and lengths\n",
        "    :param labels: a label for each character designating its position in the address\n",
        "    :param mode: indicates whether the model is being trained, evaluated or used in prediction mode\n",
        "    :param params: model hyperparameters, including rnn_size and rnn_layers\n",
        "    :return: the appropriate tf.estimator.EstimatorSpec for the model mode\n",
        "    \"\"\"\n",
        "    encoded_text, lengths = features['encoded_text'], features['lengths']\n",
        "    rnn_size = params.get(\"rnn_size\", 128)\n",
        "    rnn_layers = params.get(\"rnn_layers\", 3)\n",
        "\n",
        "    embeddings = tf.Variable(\"embeddings\", dtype=tf.float32, initializer=tf.random_normal(shape=(len(vocab), 8)))\n",
        "    encoded_strings = tf.nn.embedding_lookup(embeddings, encoded_text)\n",
        "\n",
        "    logits, loss = nnet(encoded_strings, lengths, rnn_layers, rnn_size, labels, mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "    predicted_classes = tf.argmax(logits, axis=2)\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        predictions = {\n",
        "            'class_ids': predicted_classes,\n",
        "            'probabilities': tf.nn.softmax(logits)\n",
        "        }\n",
        "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.EVAL:\n",
        "        metrics = {}\n",
        "        return tf.estimator.EstimatorSpec(\n",
        "            mode, loss=loss, eval_metric_ops=metrics)\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss, global_step=tf.train.get_global_step())\n",
        "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
        "\n",
        "\n",
        "def nnet(encoded_strings: tf.Tensor, lengths: tf.Tensor, rnn_layers: int, rnn_size: int, labels: tf.Tensor = None,\n",
        "         training: bool = True) -> (tf.Tensor, Optional[tf.Tensor]):\n",
        "    \"\"\"\n",
        "    Generates the RNN component of the model\n",
        "    :param encoded_strings: a tensor containing the encoded strings (embedding vectors)\n",
        "    :param lengths: a tensor of string lengths\n",
        "    :param rnn_layers: number of layers to use in the RNN\n",
        "    :param rnn_size: number of units in each layer\n",
        "    :param labels: labels for each character in the string (optional)\n",
        "    :param training: if True, dropout will be enabled on the RNN\n",
        "    :return: logits and loss (loss will be None if labels is not provided)\n",
        "    \"\"\"\n",
        "\n",
        "    def rnn_cell():\n",
        "        probs = 0.8 if training else 1.0\n",
        "        return tf.contrib.rnn.DropoutWrapper(tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell(rnn_size),\n",
        "                                             state_keep_prob=probs, output_keep_prob=probs)\n",
        "\n",
        "    rnn_cell_fw = tf.nn.rnn_cell.MultiRNNCell([rnn_cell() for _ in range(rnn_layers)])\n",
        "    rnn_cell_bw = tf.nn.rnn_cell.MultiRNNCell([rnn_cell() for _ in range(rnn_layers)])\n",
        "\n",
        "    (rnn_output_fw, rnn_output_bw), states = tf.nn.bidirectional_dynamic_rnn(rnn_cell_fw, rnn_cell_bw, encoded_strings,\n",
        "                                                                             lengths, dtype=tf.float32)\n",
        "    rnn_output = tf.concat([rnn_output_fw, rnn_output_bw], axis=2)\n",
        "    logits = tf.layers.dense(rnn_output, n_labels, activation=tf.nn.elu)\n",
        "\n",
        "    loss = None\n",
        "    if labels is not None:\n",
        "        mask = tf.sequence_mask(lengths, dtype=tf.float32)\n",
        "        loss = tf.losses.softmax_cross_entropy(labels, logits, weights=mask)\n",
        "    return logits, loss"
      ],
      "metadata": {
        "id": "as0s0e0O2Hvs"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import Dict, List, Union\n",
        "import textdistance\n",
        "import tensorflow as tf\n",
        "\n",
        "from addressnet.dataset import predict_input_fn, labels_list\n",
        "from addressnet.lookups import street_types, street_type_abbreviation, states, street_suffix_types, flat_types, \\\n",
        "    level_types\n",
        "from addressnet.model import model_fn\n",
        "from functools import lru_cache\n",
        "\n",
        "\n",
        "def _get_best_match(target: str, candidates: Union[List[str], Dict[str, str]], keep_idx: int = 0) -> str:\n",
        "    \"\"\"\n",
        "    Returns the most similar string to the target given a dictionary or list of candidates. If a dictionary is provided,\n",
        "    the keys and values are compared to the target, but only the requested component of the matched tuple is returned.\n",
        "    :param target: the target string to be matched\n",
        "    :param candidates: a key-value dictionary or list of strings\n",
        "    :param keep_idx: 0 to return the key, 1 to return the value of the best match (no effect if list is supplied)\n",
        "    :return: the matched string\n",
        "    \"\"\"\n",
        "    max_sim = None\n",
        "    best = None\n",
        "\n",
        "    try:\n",
        "        candidates_list = candidates.items()\n",
        "    except AttributeError:\n",
        "        candidates_list = [(i,) for i in candidates]\n",
        "        keep_idx = 0\n",
        "\n",
        "    for kv in candidates_list:\n",
        "        if target in kv:\n",
        "            return kv[keep_idx]\n",
        "\n",
        "        for i in kv:\n",
        "            similarity = _str_sim(i, target)\n",
        "            if max_sim is None or similarity > max_sim:\n",
        "                best = kv[keep_idx]\n",
        "                max_sim = similarity\n",
        "    return best\n",
        "\n",
        "\n",
        "def _str_sim(a, b, fn=textdistance.jaro_winkler):\n",
        "    \"\"\"\n",
        "    Wrapper function for the string similarity function\n",
        "    :param a: a string to compare\n",
        "    :param b: another string to compare\n",
        "    :param fn: the string similarity function from the textdistance package\n",
        "    :return: the similarity ratio\n",
        "    \"\"\"\n",
        "    return fn.normalized_similarity(a.lower(), b.lower())\n",
        "\n",
        "\n",
        "def normalise_state(s: str) -> str:\n",
        "    \"\"\"\n",
        "    Converts the state parameter to a standard non-abbreviated form\n",
        "    :param s: state string\n",
        "    :return: state name in full\n",
        "    \"\"\"\n",
        "    if s in states:\n",
        "        return states[s]\n",
        "    return _get_best_match(s, states, keep_idx=1)\n",
        "\n",
        "\n",
        "def normalise_street_type(s: str) -> str:\n",
        "    \"\"\"\n",
        "    Converts the street type parameter to a standard non-abbreviated form\n",
        "    :param s: street type string\n",
        "    :return: street type in full\n",
        "    \"\"\"\n",
        "    if s in street_types:\n",
        "        return s\n",
        "    return _get_best_match(s, street_type_abbreviation, keep_idx=0)\n",
        "\n",
        "\n",
        "def normalise_street_suffix(s: str) -> str:\n",
        "    \"\"\"\n",
        "    Converts the street suffix parameter to a standard non-abbreviated form\n",
        "    :param s: street suffix string\n",
        "    :return: street suffix in full\n",
        "    \"\"\"\n",
        "    if s in street_suffix_types:\n",
        "        return street_suffix_types[s]\n",
        "    return _get_best_match(s, street_suffix_types, keep_idx=1)\n",
        "\n",
        "\n",
        "def normalise_flat_type(s: str) -> str:\n",
        "    \"\"\"\n",
        "    Converts the flat type parameter to a standard non-abbreviated form\n",
        "    :param s: flat type string\n",
        "    :return: flat type in full\n",
        "    \"\"\"\n",
        "    if s in flat_types:\n",
        "        return s\n",
        "    return _get_best_match(s, flat_types)\n",
        "\n",
        "\n",
        "def normalise_level_type(s: str) -> str:\n",
        "    \"\"\"\n",
        "    Converts the level type parameter to a standard non-abbreviated form\n",
        "    :param s: level type string\n",
        "    :return: level type in full\n",
        "    \"\"\"\n",
        "    if s in level_types:\n",
        "        return s\n",
        "    return _get_best_match(s, level_types)\n",
        "\n",
        "\n",
        "@lru_cache(maxsize=2)\n",
        "def _get_estimator(model_fn, model_dir):\n",
        "    return tf.estimator.Estimator(model_fn=model_fn,\n",
        "                                  model_dir=model_dir)\n",
        "\n",
        "\n",
        "def predict_one(address: str, model_dir: str = None) -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Segments a given address into its components and attempts to normalise categorical components,\n",
        "    e.g. state, street type\n",
        "    :param address: the input address string\n",
        "    :param model_dir: path to trained model\n",
        "    :return: a dictionary with the address components separated\n",
        "    \"\"\"\n",
        "    return next(predict([address], model_dir))\n",
        "\n",
        "\n",
        "def predict(address: List[str], model_dir: str = None) -> List[Dict[str, str]]:\n",
        "    \"\"\"\n",
        "    Segments a set of addresses into their components and attempts to normalise categorical components,\n",
        "    e.g. state, street type\n",
        "    :param address: the input list of address strings\n",
        "    :param model_dir: path to trained model\n",
        "    :return: a list of dictionaries with the address components separated\n",
        "    \"\"\"\n",
        "    if model_dir is None:\n",
        "        model_dir = os.path.join(os.path.dirname(__file__), 'pretrained')\n",
        "    assert os.path.isdir(model_dir), \"invalid model_dir provided: %s\" % model_dir\n",
        "    address_net_estimator = _get_estimator(model_fn, model_dir)\n",
        "    result = address_net_estimator.predict(predict_input_fn(address))\n",
        "    class_names = [l.replace(\"_code\", \"\") for l in labels_list]\n",
        "    class_names = [l.replace(\"_abbreviation\", \"\") for l in class_names]\n",
        "    for addr, res in zip(address, result):\n",
        "        mappings = dict()\n",
        "        for char, class_id in zip(addr.upper(), res['class_ids']):\n",
        "            if class_id == 0:\n",
        "                continue\n",
        "            cls = class_names[class_id - 1]\n",
        "            mappings[cls] = mappings.get(cls, \"\") + char\n",
        "\n",
        "        if 'state' in mappings:\n",
        "            mappings['state'] = normalise_state(mappings['state'])\n",
        "        if 'street_type' in mappings:\n",
        "            mappings['street_type'] = normalise_street_type(mappings['street_type'])\n",
        "        if 'street_suffix' in mappings:\n",
        "            mappings['street_suffix'] = normalise_street_suffix(mappings['street_suffix'])\n",
        "        if 'flat_type' in mappings:\n",
        "            mappings['flat_type'] = normalise_flat_type(mappings['flat_type'])\n",
        "        if 'level_type' in mappings:\n",
        "            mappings['level_type'] = normalise_level_type(mappings['level_type'])\n",
        "\n",
        "        yield mappings"
      ],
      "metadata": {
        "id": "mees6Dd_2Mpb"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Contains nearby characters on the keyboard for substitution when generating typos\n",
        "character_replacement = dict()\n",
        "\n",
        "character_replacement['a'] = 'qwsz'\n",
        "character_replacement['b'] = 'nhgv '\n",
        "character_replacement['c'] = 'vfdx '\n",
        "character_replacement['d'] = 'fresxc'\n",
        "character_replacement['e'] = 'sdfr43ws'\n",
        "character_replacement['f'] = 'gtrdcv'\n",
        "character_replacement['g'] = 'hytfvb'\n",
        "character_replacement['h'] = 'juytgbn'\n",
        "character_replacement['i'] = 'ujklo98'\n",
        "character_replacement['j'] = 'mkiuyhn'\n",
        "character_replacement['k'] = 'jm,loij'\n",
        "character_replacement['l'] = 'k,.;pok'\n",
        "character_replacement['m'] = 'njk, '\n",
        "character_replacement['n'] = 'bhjm '\n",
        "character_replacement['o'] = 'plki90p'\n",
        "character_replacement['p'] = 'ol;[-0o'\n",
        "character_replacement['q'] = 'asw21'\n",
        "character_replacement['r'] = 'tfde45'\n",
        "character_replacement['s'] = 'dxzawe'\n",
        "character_replacement['t'] = 'ygfr56'\n",
        "character_replacement['u'] = 'ijhy78'\n",
        "character_replacement['v'] = 'cfgb '\n",
        "character_replacement['w'] = 'saq23e'\n",
        "character_replacement['x'] = 'zsdc'\n",
        "character_replacement['y'] = 'uhgt67'\n",
        "character_replacement['z'] = 'xsa'\n",
        "character_replacement['1'] = '2q'\n",
        "character_replacement['2'] = '3wq1'\n",
        "character_replacement['3'] = '4ew2'\n",
        "character_replacement['4'] = '5re3'\n",
        "character_replacement['5'] = '6tr4'\n",
        "character_replacement['6'] = '7yt5'\n",
        "character_replacement['7'] = '8uy6'\n",
        "character_replacement['8'] = '9iu7'\n",
        "character_replacement['9'] = '0oi8'\n",
        "character_replacement['0'] = '-po9'\n",
        "\n",
        "\n",
        "def generate_typo(s: str, sub_rate: float = 0.01, del_rate: float = 0.005, dupe_rate: float = 0.005,\n",
        "                  transpose_rate: float = 0.01) -> str:\n",
        "    \"\"\"\n",
        "    Generates a new string containing some plausible typos\n",
        "    :param s: the input string\n",
        "    :param sub_rate: character substitution rate (0 < x < 1)\n",
        "    :param del_rate: character deletion rate (0 < x < 1)\n",
        "    :param dupe_rate: character duplication rate (0 < x < 1)\n",
        "    :param transpose_rate: character transposition rate (0 < x < 1)\n",
        "    :return: the string with typos\n",
        "    \"\"\"\n",
        "    if len(s) == 0:\n",
        "        return s\n",
        "\n",
        "    new_string = list()\n",
        "    for i, char in enumerate(s.lower()):\n",
        "\n",
        "        # Decide what to do\n",
        "        do = np.random.uniform(size=(4,))\n",
        "        do_swap = do[0] < sub_rate\n",
        "        do_delete = do[1] < del_rate\n",
        "        do_duplicate = do[2] < dupe_rate\n",
        "        do_transpose = do[3] < transpose_rate\n",
        "\n",
        "        if do_swap and char in character_replacement:\n",
        "            # Exchange the character for a randomly selected replacement of nearby keys\n",
        "            new_string.append(random.choice(character_replacement[char]))\n",
        "        elif do_delete:\n",
        "            # Don't include this character in the replacement string\n",
        "            continue\n",
        "        elif do_duplicate:\n",
        "            # Add this character twice to the new string\n",
        "            new_string.extend([char] * 2)\n",
        "        elif do_transpose and len(new_string) > 0:\n",
        "            # Swap this and the previous character\n",
        "            new_string.append(new_string[-1])\n",
        "            new_string[-2] = char\n",
        "        else:\n",
        "            # Keep the character\n",
        "            new_string.append(char)\n",
        "\n",
        "    # if an empty string is generated, give it another go\n",
        "    if len(new_string) == 0:\n",
        "        return generate_typo(s, sub_rate, del_rate, dupe_rate, transpose_rate)\n",
        "\n",
        "    return ''.join(new_string)"
      ],
      "metadata": {
        "id": "B4Qyiz8Z2Ryh"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the predict_one function\n",
        "from addressnet.predict import predict_one\n",
        "\n",
        "# Run the prediction on a sample address\n",
        "if __name__ == \"__main__\":\n",
        "                  print(predict_one(\"casa del gelato, 10A 24-26 high street road mount waverley vic 3183\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "NbDYzmKp2TH2",
        "outputId": "3d63c48d-b4d8-4a3a-f6f0-1229632fb11c"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-b5db89b80151>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Run the prediction on a sample address\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"casa del gelato, 10A 24-26 high street road mount waverley vic 3183\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/addressnet/predict.py\u001b[0m in \u001b[0;36mpredict_one\u001b[0;34m(address, model_dir)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0maddress\u001b[0m \u001b[0mcomponents\u001b[0m \u001b[0mseparated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \"\"\"\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/addressnet/predict.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(address, model_dir)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_code\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_abbreviation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0maddr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0mmappings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_fn, predict_keys, hooks, checkpoint_path, yield_single_examples)\u001b[0m\n\u001b[1;32m    621\u001b[0m         features, input_hooks = self._get_features_from_input_fn(\n\u001b[1;32m    622\u001b[0m             input_fn, ModeKeys.PREDICT)\n\u001b[0;32m--> 623\u001b[0;31m         estimator_spec = self._call_model_fn(features, None, ModeKeys.PREDICT,\n\u001b[0m\u001b[1;32m    624\u001b[0m                                              self.config)\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/addressnet/model.py\u001b[0m in \u001b[0;36mmodel_fn\u001b[0;34m(features, labels, mode, params)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mrnn_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rnn_layers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"embeddings\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mencoded_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_lookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'get_variable'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from addressnet.predict import predict_one\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(predict_one(\"casa del gelato, 10A 24-26 high street road mount waverley vic 3183\"))"
      ],
      "metadata": {
        "id": "roz7_GwM525w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}